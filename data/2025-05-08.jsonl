{"id": "2505.03927", "pdf": "https://arxiv.org/pdf/2505.03927", "abs": "https://arxiv.org/abs/2505.03927", "authors": ["Snir Pardo", "Dovi Poznanski", "Steve Croft", "Andrew P. V. Siemion", "Matthew Lebofsky"], "title": "Using anomaly detection to search for technosignatures in Breakthrough Listen observations", "categories": ["astro-ph.IM"], "comment": "AJ accepted", "summary": "We implement a machine learning algorithm to search for extra-terrestrial\ntechnosignatures in radio observations of several hundred nearby stars,\nobtained with the Parkes and Green Bank Telescopes by the Breakthrough Listen\ncollaboration. Advances in detection technology have led to an exponential\ngrowth in data, necessitating innovative and efficient analysis methods. This\nproblem is exacerbated by the large variety of possible forms an\nextraterrestrial signal might take, and the size of the multidimensional\nparameter space that must be searched. It is then made markedly worse by the\nfact that our best guess at the properties of such a signal is that it might\nresemble the signals emitted by human technology and communications, the main\n(yet diverse) contaminant in radio observations. We address this challenge by\nusing a combination of simulations and machine learning methods for anomaly\ndetection. We rank candidates by how unusual they are in frequency, and how\npersistent they are in time, by measuring the similarity between consecutive\nspectrograms of the same star. We validate that our filters significantly\nimprove the quality of the candidates that are selected for human vetting when\ncompared to a random selection. Of the ~ 10^11 spectrograms that we analyzed,\nwe visually inspected thousands of the most promising spectrograms, and\nthousands more for validation, about 20,000 in total, and report that no\ncandidate survived basic scrutiny."}
{"id": "2505.03932", "pdf": "https://arxiv.org/pdf/2505.03932", "abs": "https://arxiv.org/abs/2505.03932", "authors": ["Carter Lee Rhea", "Pieter Van Dokkum", "Steven R. Janssens", "Imad Pasham", "Roberto Abraham", "William P Bowman", "Deborah Lokhorst", "Seery Chen"], "title": "dfreproject: A Python package for astronomical reprojection", "categories": ["astro-ph.IM"], "comment": "Submitted to JOSS Related code and documentation can be found at\n  https://github.com/DragonflyTelescope/dfreproject", "summary": "Deep astronomical images are often constructed by digitially stacking many\nindividual sub-exposures. Each sub-exposure is expected to show small\ndifferences in the positions of stars and other objects in the field, due to\nthe movement of the celestial bodies, changes/imperfections in the\nopto-mechanical imaging train, and other factors. To maximize image quality,\none must ensure that each sub-exposure is aligned to a common frame of\nreference prior to stacking. This is done by reprojecting each exposure onto a\ncommon target grid defined using a World Coordinate System (WCS) that is\ndefined by mapping the known angular positions of reference objects to their\nobserved spatial positions on each image. The transformations needed to\nreproject images involve complicated trigonometric expressions which can be\nslow to compute, so reprojection can be a major bottleneck in image processing\npipelines.\n  To make astronomical reprojections faster to implement in pipelines, we have\nwritten `dfreproject`, a Python package of GPU-optimized functions for this\npurpose. The package's functions break down coordinate transformations using\nGnomonic projections to define pixel-by-pixel shifts from the source to the\ntarget plane. The package also provides tools for interpolating a source image\nonto a target plane with a single function call. This module follows the FITS\nand SIP formats laid out in the seminal papers. Compared to common\nalternatives, `dfreproject`'s routines result in speedups of up to 20X when run\non a GPU and 10X when run on a CPU."}
{"id": "2505.04239", "pdf": "https://arxiv.org/pdf/2505.04239", "abs": "https://arxiv.org/abs/2505.04239", "authors": ["Jean-Marie Malherbe"], "title": "High polarization lines of the second solar spectrum of the Solar limb", "categories": ["astro-ph.IM", "astro-ph.SR"], "comment": null, "summary": "We present a dataset of high resolution spectra of the Sun of many strongly\npolarized lines belonging to the second solar spectrum, i.e. the spectrum near\nthe limb in linear polarization (scattering polarization). These solar spectra\nwere obtained in full Stokes polarimetry (I, Q/I, U/I, V/I) in the quiet Sun at\nvarious distances from the limb, and at disk centre for comparison, with the\nground based CNRS THEMIS telescope. Polarization rates Q/I up to 7% are\nobtained in CaI 4227 {\\AA} line at $\\mu$ = cos$\\theta$ = 0, while 2% is reached\nin SrI 4607 {\\AA} line and 1.4% in BaII 4554 {\\AA}. The spectra shown here are\nfreely available in FITS format to the research community."}
{"id": "2505.03849", "pdf": "https://arxiv.org/pdf/2505.03849", "abs": "https://arxiv.org/abs/2505.03849", "authors": ["Jonathan Gorard", "Ammar Hakim", "Hong Qin", "Kyle Parfrey", "Shantenu Jha"], "title": "Improved Dimensionality Reduction for Inverse Problems in Nuclear Fusion and High-Energy Astrophysics", "categories": ["cs.LG", "astro-ph.IM", "nucl-th"], "comment": "2 pages. Position paper accepted to DOE-ASCR Inverse Methods for\n  Complex Systems under Uncertainty Workshop (Rockville, MD, United States,\n  June 10-12, 2025)", "summary": "Many inverse problems in nuclear fusion and high-energy astrophysics\nresearch, such as the optimization of tokamak reactor geometries or the\ninference of black hole parameters from interferometric images, necessitate\nhigh-dimensional parameter scans and large ensembles of simulations to be\nperformed. Such inverse problems typically involve large uncertainties, both in\nthe measurement parameters being inverted and in the underlying physics models\nthemselves. Monte Carlo sampling, when combined with modern non-linear\ndimensionality reduction techniques such as autoencoders and manifold learning,\ncan be used to reduce the size of the parameter spaces considerably. However,\nthere is no guarantee that the resulting combinations of parameters will be\nphysically valid, or even mathematically consistent. In this position paper, we\nadvocate adopting a hybrid approach that leverages our recent advances in the\ndevelopment of formal verification methods for numerical algorithms, with the\ngoal of constructing parameter space restrictions with provable mathematical\nand physical correctness properties, whilst nevertheless respecting both\nexperimental uncertainties and uncertainties in the underlying physical\nprocesses."}
{"id": "2505.03881", "pdf": "https://arxiv.org/pdf/2505.03881", "abs": "https://arxiv.org/abs/2505.03881", "authors": ["Drake Deming", "Miles H. Currie", "Victoria S. Meadows", "Sarah Peacock"], "title": "Minimizing Star Spot Contamination of Exoplanet Transit Spectroscopy Using Alternate Normalization", "categories": ["astro-ph.EP", "astro-ph.IM", "astro-ph.SR"], "comment": "17 pages, 15 figures, accepted for the Astronomical Journal", "summary": "Recently, Currie et al. simulated the detection of molecules in the\natmospheres of temperate rocky exoplanets transiting nearby M-dwarf stars. They\nsimulated detections via spectral cross-correlation applied to high resolution\noptical and near-IR transit spectroscopy using the ELTs. Currie et al. did not\nconsider the effect of unocculted star spots, but we do that here for possible\ndetections of molecular oxygen, carbon dioxide, methane, and water vapor. We\nfind that confusion noise from unocculted star spots becomes significant for\nlarge programs that stack tens to hundreds of transits to detect these\nmolecules. Noise from star spots increases with greater spot filling factors,\nand star spot temperature has less effect than filling factor. Nevertheless,\nmolecular oxygen, carbon dioxide, and methane could be detected in temperate\nrocky planets transiting nearby M-dwarfs without correcting for star spots.\nWater vapor detections are the most affected, with star spots contaminating the\nexoplanet signal as well as producing extra noise. Unocculted spots only affect\ntransit spectroscopy when normalizing by dividing by the total flux from the\nstar. We describe an alternate normalization method that minimizes star spot\neffects by deriving and implementing an unspotted proxy spectrum for the\nnormalization. We show that the method works in principle using realistic\nlevels of random observational noise. Alternate normalization would be broadly\napplicable to all types of transit spectroscopy, and we discuss challenges to\napplying it in practice. We also outline a comprehensive approach that has the\npotential to overcome those challenges."}
{"id": "2505.03936", "pdf": "https://arxiv.org/pdf/2505.03936", "abs": "https://arxiv.org/abs/2505.03936", "authors": ["Neerav Kaushal", "Elena Giusarma", "Mauricio Reyes"], "title": "nuGAN: Generative Adversarial Emulator for Cosmic Web with Neutrinos", "categories": ["astro-ph.CO", "astro-ph.IM"], "comment": "14 pages, 5 figures, 4 tables", "summary": "Understanding the impact of neutrino masses on the evolution of Universe is a\ncrucial aspect of modern cosmology. Due to their large free streaming lengths,\nneutrinos significantly influence the formation of cosmic structures at\nnon-linear scales. To maximize the information yield from current and future\ngalaxy surveys, it is essential to generate precise theoretical predictions of\nstructure formation. One approach to achieve this is by running large sets of\ncosmological numerical simulations, which is a computationally intensive\nprocess. In this study, we propose a deep learning-based generative adversarial\nnetwork (GAN) model to emulate the Universe for a variety of neutrino masses.\nOur model called $\\nu$GAN (for neutrino GAN) is able to generate 2D cosmic webs\nof the Universe for a number of neutrino masses ranging from 0.0 eV to 0.4 eV.\nThe generated maps exhibit statistical independence, lack correlations with\ntraining data, and very closely resemble the distribution of matter in true\nmaps. We assess the accuracy of our results both visually and through key\nstatistics used in cosmology and computer vision analyses. Our results indicate\nthat samples generated by $\\nu$GAN are accurate within a 5% error on power\nspectrum between k=0.01 to k=0.5 h/Mpc. Although this accuracy covers the\nmildly non-linear scales, consistent with other works and observations,\nachieving higher accuracy at fully non-linear scales requires more\nsophisticated models, such as diffusion models. Nevertheless, our work opens up\nnew avenues for building emulators to generate fast and massive neutrino\nsimulations, potentially revolutionizing cosmological predictions and analyses.\nThis work serves as a proof-of-concept, paving the way for future extensions\nwith higher-resolution 3D data and advanced generative models."}
{"id": "2505.03994", "pdf": "https://arxiv.org/pdf/2505.03994", "abs": "https://arxiv.org/abs/2505.03994", "authors": ["Nicholas F. Wogan", "James Mang", "Natasha E. Batalha", "Sagnick Mukherjee", "Channon Visscher", "Jonathan J. Fortney", "Mark S. Marley", "Caroline V. Morley"], "title": "The Sonora Substellar Atmosphere Models. V: A Correction to the Disequilibrium Abundance of CO$_2$ for Sonora Elf Owl", "categories": ["astro-ph.EP", "astro-ph.IM"], "comment": "Submitted for publication in a AAS journal", "summary": "To aid the interpretation of observations of substellar atmospheres,\nMukherjee et al. (2024) created the Sonora Elf Owl grid of model atmospheres,\nsimulations that accounted for disequilibrium quench chemistry. However, Sonora\nElf Owl did not accurately estimate CO$_2$ quenching because the models\nquenched the gas with respect to the full atmosphere equilibrium, but CO$_2$\nshould have instead been quenched with respect to the disequilibrium (i.e.,\nquenched) abundance of CO. As a result, Sonora Elf Owl under-predicted the\nCO$_2$ abundance by several order of magnitude in some instances, an amount\nthat JWST is sensitive to. Here, we release version two of the Sonora Elf Owl\ngrid which has corrected CO$_2$ concentrations. Additionally, in version two we\nremove PH$_3$ as a spectral contributor since our spectra consistently\ncontained too much PH$_3$ absorption. The new spectra can be found as an update\nto the original Zenodo postings."}
{"id": "2505.04067", "pdf": "https://arxiv.org/pdf/2505.04067", "abs": "https://arxiv.org/abs/2505.04067", "authors": ["Min-Yu Li", "Sheng-Bang Qian", "Li-Ying Zhu", "Wen-Ping Liao", "Lin-Feng Chang", "Er-Gang Zhao", "Xiang-Dong Shi", "Fu-Xing Li", "Qi-Bin Sun", "Ping Li"], "title": "Heartbeat Stars Recognition Based on Recurrent Neural Networks: Method and Validation", "categories": ["astro-ph.SR", "astro-ph.IM"], "comment": "10pages,5figures", "summary": "Since the variety of their light curve morphologies, the vast majority of the\nknown heartbeat stars (HBSs) have been discovered by manual inspection. Machine\nlearning, which has already been successfully applied to the classification of\nvariable stars based on light curves, offers another possibility for the\nautomatic detection of HBSs. We propose a novel feature extraction approach for\nHBSs. First, the light curve is transformed into the frequency domain via\nFourier transform, then the amplitudes of the first 100 harmonics are\nextracted, and finally these harmonics are normalised as feature vectors of the\nlight curve. A training data set of synthetic light curves is constructed using\nELLC, and their features are fed into recurrent neural networks (RNNs) for\nsupervised learning, with the expected output being the eccentricity of these\nlight curves. The performance of RNNs is evaluated using a test data set of\nsynthetic light curves, achieving 95$\\%$ accuracy. When applied to known HBSs\nfrom OGLE, Kepler, and TESS surveys, the networks achieve an average accuracy\nof 88$\\%$. This method successfully identify four new HBSs within the eclipsing\nbinary catalog of Kirk et al. The use of orbital harmonics as features for HBSs\nproves to be an effective approach that significantly reduces the computational\ncost of neural networks. RNNs show excellent performance in recognising this\ntype of time series data. This method not only allows efficient identification\nof HBSs, but can also be extended to recognise other types of periodic variable\nstars."}
{"id": "2505.04399", "pdf": "https://arxiv.org/pdf/2505.04399", "abs": "https://arxiv.org/abs/2505.04399", "authors": ["Tiger Lu", "Haniyeh Tajer", "David M. Hernandez", "Hanno Rein", "Yurou Liu", "Malena Rice"], "title": "Collisional Fragmentation Support in TRACE", "categories": ["astro-ph.EP", "astro-ph.IM"], "comment": "Accepted in RNAAS", "summary": "We present improved collision support for TRACE, a state-of-the-art hybrid\nintegrator in REBOUND. TRACE now supports collisional fragmentation and can\nhandle both removing and adding particles mid-timestep. We describe the\nback-end logic implemented for robust collision support, and compare TRACE's\nperformance to other integrators including MERCURIUS on a large-N\nprotoplanetary disk simulation with various collision prescriptions, a system\nwhich TRACE previously could not handle. TRACE matches the behavior of these\nintegrators, while offering potentially vast speedups of over 70x. All updates\ndescribed in this Note are available with the most recent public release of\nREBOUND."}
{"id": "2505.04413", "pdf": "https://arxiv.org/pdf/2505.04413", "abs": "https://arxiv.org/abs/2505.04413", "authors": ["Avinash Verma", "Jayesh Goyal", "Swaroop Avarsekar", "Gaurav Shukla"], "title": "A Detailed Investigation of HD 209458 b HST & JWST Transmission Spectra with SANSAR", "categories": ["astro-ph.EP", "astro-ph.IM"], "comment": "Accepted for Publication in The Astronomical Journal (AJ). 39 pages\n  and 20 Figures", "summary": "HD 209458 b is the first exoplanet on which an atmosphere was detected. Since\nthen, its atmosphere has been investigated using multiple telescopes and\ninstruments. However, many of its atmospheric constraints remain debatable.\nWhile HST observations suggested a highly sub-solar metallicity, recent JWST\nNIRCam observations by Xue et al. 2024 constrained a super-solar metallicity\nwith highly sub-solar C/O. In this work, we show a detailed investigation of HD\n209458 b transmission spectra observations from JWST and HST using SANSAR, a\nnewly developed planetary atmosphere modeling framework, with free, equilibrium\nchemistry and self-consistent grid retrievals. The overall best-fitting model\nwith free retrievals ($\\chi^2_{\\rm{red}}$=1.21) constrains its metallicity and\nC/O to be highly sub-solar, while equilibrium chemistry and grid retrievals\n($\\chi^2_{\\rm{red}}$=1.27 and 1.30, respectively) are consistent with solar\nvalues using STIS+WFC3+NIRCam observations. The retrieved abundances of H$_2$O\nand CO$_2$ are almost three orders of magnitude lower (highly sub-solar) with\nSTIS+WFC3+NIRCam compared to just NIRCam, using free retrievals. NIRCam\nobservations alone also result in misleading constraints on metallicity and\nC/O, with equilibrium chemistry and grid retrieval. We find that the model\nchoice of varying C/H or O/H to vary the C/O in equilibrium chemistry\nretrievals leads to different metallicity constraints with NIRCam, but similar\nconstraints with STIS+WFC3+NIRCam. We conclude that NIRCam observations alone\ncan lead to overestimation of abundances for exoplanet atmospheres and,\ntherefore, should be used in combination with UV/Optical and near-infrared\nobservations to obtain robust constraints on abundances, C/O, and metallicity.\nSpecifically, even though we can detect the CO$_2$ feature with just NIRCam, we\ncannot constrain its abundances robustly without the optical baseline."}
{"id": "2505.04437", "pdf": "https://arxiv.org/pdf/2505.04437", "abs": "https://arxiv.org/abs/2505.04437", "authors": ["Jennifer Rosina Andersson", "Oleg Kochukhov", "Zheng Zhao", "Jens Sj√∂lund"], "title": "Probabilistic Zeeman-Doppler imaging of stellar magnetic fields: I. Analysis of tau Scorpii in the weak-field limit", "categories": ["astro-ph.SR", "astro-ph.IM"], "comment": "Accepted for publication in A&A", "summary": "Zeeman-Doppler imaging (ZDI) is used to study the surface magnetic field\ntopology of stars, based on high-resolution spectropolarimetric time series\nobservations. Multiple ZDI inversions have been conducted for the early B-type\nstar tau Sco, which has been found to exhibit a weak but complex non-dipolar\nsurface magnetic field. The classical ZDI framework suffers from a significant\nlimitation in that it provides little to no reliable uncertainty quantification\nfor the reconstructed magnetic field maps, with essentially all published\nresults being confined to point estimates. To fill this gap, we propose a\nBayesian framework for probabilistic ZDI. Here, the proposed framework is\ndemonstrated on tau Sco in the weak-field limit. We propose three distinct\nstatistical models, and use archival ESPaDOnS high-resolution Stokes V\nobservations to carry out the probabilistic magnetic inversion in closed form.\nThe surface magnetic field is parameterised by a high-dimensional\nspherical-harmonic expansion. By comparing three different prior distributions\nover the latent variables in the spherical-harmonic decomposition, our results\nshowcase the ZDI sensitivity to various hyperparameters. The mean magnetic\nfield maps are qualitatively similar to previously published point estimates,\nbut analysis of the magnetic energy distribution indicates high uncertainty and\nhigher energy content at low angular degrees l. Our results effectively\ndemonstrate that, for stars in the weak-field regime, reliable uncertainty\nquantification of recovered magnetic field maps can be obtained in closed form\nwith natural assumptions on the statistical model. Future work will explore\nextending this framework beyond the weak-field approximation and incorporating\nprior uncertainty over multiple stellar parameters in more complex magnetic\ninversion problems."}
